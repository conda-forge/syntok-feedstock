{% set name = "syntok" %}
{% set version = "1.3.2" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: 85547cddb6b0766de5b45514d08fb82034eef1fb3ca4c2252fa82cd99901dc04

build:
  number: 0
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv

requirements:
  host:
    - pip
    - python >=3.5
  run:
    - python >=3.5
    - regex

test:
  imports:
    - syntok
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://github.com/fnl/syntok
  summary: sentence segmentation and word tokenization toolkit
  description: |
    Syntok is the successor of an earlier, very similar tool, segtok, but has evolved
    significantly in terms of providing better segmentation and tokenization performance
    and throughput (syntok can segment documents at a rate of about 100k tokens per
    second without problems). For example, if a sentence terminal marker is not
    followed by a spacing character, segtok is unable to detect that as a terminal
    marker, while syntok has no problem segmenting that case (as it uses tokenization
    first, and does segmentation afterwards).
  license: MIT
  license_family: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - BastianZim
